---
title: "p8105_hw5_jak2312"
author: "Jared Klug"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
```

## Problem 1

Read and clean df
```{r}
homicide_df = 
  read_csv("./data/homicide/homicide-data.csv") %>% 
  mutate(
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved"
    ),
    city_state = str_c(city, state, sep = "_")
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```

create aggregate df
```{r}
aggregate_df = 
  homicide_df %>% 
    group_by(city_state) %>% 
    summarize(
      hom_total = n(),
      hom_unsolved = sum(resolved == "unsolved")
    ) 
```

run prop test for 1 city
```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved),
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)
) %>% broom::tidy()
```

itterate over all the cities
```{r}
results_df = 
  aggregate_df %>% 
    mutate(
      prop_test = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
      tidy_test = map(prop_test, broom::tidy)
    ) %>% 
    select(-prop_test) %>% 
    unnest(tidy_test) %>% 
    select(city_state, estimate, conf.low, conf.high)
```

Arrange by estimate
```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

## Problem 2

```{r read_combine_df}
study_data = tibble(
    filename = list.files("./data/longitudinal_study/"),
    subject_data = map(str_c("./data/longitudinal_study/", filename), read.csv)
  ) %>% 
  separate(filename, into = c("arm", "subject_id"), sep = "_") %>% 
  mutate(subject_id = str_replace(subject_id, ".csv", ""),
         subject_id = as.numeric(subject_id),
         subject_id = ifelse(str_detect(arm, "exp"), subject_id + 10, subject_id))
```

```{r tidy_df}
pat_data_long = function(df){
  df %>% pivot_longer(week_1:week_8,
                      names_to = "week",
                      names_prefix = "week_",
                      values_to = "data")
}

for(i in 1:20){
  study_data$subject_data[[i]] = pat_data_long(study_data$subject_data[[i]])
}

study_data
study_data$subject_data[[1]]
```

```{r plot_data_vs_week}

study_data %>% 
  unnest(subject_data) %>% 
  ggplot(aes(x = week, y = data, group = subject_id)) +
  geom_line(aes(color = arm))

```

We can see that subjects in both the experimental arm and control arm have points that fluctuate throughout the 8 weeks. However, we can observe a general upwards trend in the experimental arm which can indicate that the treatment these subjects are getting is influencing the data. The control arm data fluctuates heavily but there does not appear to be an overall change in the output reading. 

## Problem 3

```{r simulation}

mean_power = function(n = 30, mu, sigma = 5){
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma)
    )
  
  sim_data %>% 
    summarize(
      mu_hat = mean(x),
      p_value = t.test(x) %>% broom::tidy() %>% select(p.value)
    ) %>% 
    mutate(null_reject = ifelse(p_value$p.value < 0.05, 1, 0))
}

set.seed(5432)

results = 
  tibble(true_mu = c(0,1,2,3,4,5,6)) %>% 
  mutate(
    output_list = map(.x = true_mu, ~rerun(5000, mean_power(mu = .x))),
    sim_results = map(output_list, bind_rows)
  ) %>% 
  select(-output_list) %>% 
  unnest(sim_results) 
```

```{r power_vs_true_mu}
results %>% 
  mutate(
    true_mu = str_c("mu = ", true_mu),
    true_mu = fct_inorder((true_mu))
  ) %>% 
   group_by(true_mu) %>%
   summarize(
     power = sum(null_reject)/5000
   ) %>% 
  ggplot(aes(x = true_mu, y = power)) +
  geom_point()
  
```

As the true mean of the source population increases, the power of the t.test function increases to 1. This is expected as the t.test is testing the null hypothesis that the sample mean is equal to 0. I am surprised that at a sample from a population of mean 3 still had some one sample t test show that the sample mean is 0. 

```{r mu_hat_vs_true_mu}

results %>% 
  mutate(
    true_mu = str_c("mu = ", true_mu),
    true_mu = fct_inorder((true_mu))
  ) %>% 
   group_by(true_mu) %>%
   summarize(
     avg_mu_hat = sum(mu_hat)/5000,
     num_reject = sum(null_reject),
     rej_mu_hat = sum(subset(mu_hat, null_reject == 1))/num_reject
   ) %>% 
  ggplot(aes(x = true_mu)) +
  geom_point(aes(y = avg_mu_hat, color = "all avg mu hat"), shape = 0) +
  geom_point(aes(y = rej_mu_hat, color = "rejected mu hat"), shape = 4) +
  labs(x = "True Mu", y = "Mu hat")

```

The rejected mu hat values do not approximately equal the true value of mu except for when we get to a true mu value of 4 and above. This is expected as for the smaller populations (true mu 1 to 3), the samples had tests that did not reject the null, which means that their specific sample average was higher than true mu. For a true mu of 0, we see that it was mostly the extreme negative sample mu that rejected the null hypothesis in a one sample t test, resulting in a rejected mu hat lower than the all avg mu hat. At a true mu of 5 and 6 the rejected mu hat is equal to the all average mu hat which approximates the population mu because we had a 100% rejection rate for these populations.

